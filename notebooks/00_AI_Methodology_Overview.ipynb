{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM AI Methodology - Fruit Ripeness Classifier\n",
    "\n",
    "**Student:** Maria Paula Salazar Agudelo  \n",
    "**Course:** AI Minor - Personal Challenge  \n",
    "**Date:** 2025\n",
    "\n",
    "---\n",
    "\n",
    "## What is this notebook?\n",
    "\n",
    "This notebook shows how I applied the IBM AI Methodology (10 steps) to my fruit ripeness classification project.\n",
    "\n",
    "For each step, I'll explain:\n",
    "- What the step means\n",
    "- How I applied it to my project\n",
    "- What I learned or discovered\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Business Understanding\n",
    "\n",
    "**What it means:** Understand the problem you're trying to solve and why it matters.\n",
    "\n",
    "### My Problem\n",
    "\n",
    "**The situation:**\n",
    "- When shopping for fruit, it's hard to tell if it's ripe, overripe, or not ready yet\n",
    "- People often buy fruit that goes bad quickly or tastes bad\n",
    "- This wastes money and food\n",
    "\n",
    "**What I want to build:**\n",
    "A mobile app where you take a photo of fruit and it tells you:\n",
    "- **Fresh** â†’ Good to buy now\n",
    "- **Rotten** â†’ Don't buy\n",
    "- **Unripe** â†’ Wait a few days\n",
    "\n",
    "**Why it matters:**\n",
    "- Helps people buy better fruit\n",
    "- Reduces food waste\n",
    "- Saves money\n",
    "\n",
    "**Target users:** Anyone who shops for groceries (especially people like me who aren't good at picking fruit!)\n",
    "\n",
    "**Success criteria:** Model accuracy â‰¥ 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analytic Approach\n",
    "\n",
    "**What it means:** Decide what type of AI/ML technique will solve the problem.\n",
    "\n",
    "### My Approach\n",
    "\n",
    "**Problem type:** Image classification\n",
    "\n",
    "**Why image classification?**\n",
    "- I have images of fruit\n",
    "- I need to classify them into categories (fresh/rotten/unripe)\n",
    "- This is a supervised learning problem\n",
    "\n",
    "**Technique chosen:** Convolutional Neural Network (CNN) with Transfer Learning\n",
    "\n",
    "**Why CNNs?**\n",
    "- CNNs are designed for image data\n",
    "- They can learn visual patterns (color, texture, spots, bruises)\n",
    "- They're proven to work well for image classification\n",
    "\n",
    "**Why Transfer Learning?**\n",
    "- Training from scratch takes weeks and huge datasets\n",
    "- Pre-trained models (like MobileNetV2) already know how to \"see\" (detect edges, shapes, colors)\n",
    "- I only need to teach it my specific fruits - much faster!\n",
    "\n",
    "**Model selected:** MobileNetV2\n",
    "- Lightweight (works on mobile phones)\n",
    "- Fast inference\n",
    "- Good accuracy\n",
    "- Pre-trained on ImageNet (1.4M images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Requirements\n",
    "\n",
    "**What it means:** Figure out what data you need to solve the problem.\n",
    "\n",
    "### What Data I Need\n",
    "\n",
    "**Type of data:** Images of fruit\n",
    "\n",
    "**Categories needed:**\n",
    "- 3 fruit types: Apples, Bananas, Oranges (common fruits everyone buys)\n",
    "- 3 ripeness stages: Fresh, Rotten, Unripe\n",
    "- Total: 9 classes (3 fruits Ã— 3 stages)\n",
    "\n",
    "**Data characteristics needed:**\n",
    "- Different lighting conditions (store lights, natural light)\n",
    "- Different angles (top view, side view)\n",
    "- Different backgrounds\n",
    "- Various fruit sizes\n",
    "- Clear ripeness indicators visible (brown spots for rotten, green for unripe, etc.)\n",
    "\n",
    "**Quantity needed:**\n",
    "- Minimum: 500+ images per class (for basic training)\n",
    "- Ideal: 1000+ images per class (for good accuracy)\n",
    "- My target: ~2000 images per class\n",
    "\n",
    "**Train/Test split:**\n",
    "- Training: 80% (to train the model)\n",
    "- Testing: 20% (to evaluate performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Collection\n",
    "\n",
    "**What it means:** Actually get the data you need.\n",
    "\n",
    "### How I Got My Data\n",
    "\n",
    "**Source:** Kaggle - \"Fruit Ripeness Dataset\"\n",
    "\n",
    "**Why this dataset?**\n",
    "- Already labeled with ripeness stages\n",
    "- Contains apples, bananas, oranges\n",
    "- ~20,000 images total\n",
    "- Free and public (no copyright issues)\n",
    "- Already split into train/test folders\n",
    "\n",
    "**Dataset structure:**\n",
    "```\n",
    "data/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ freshapples/\n",
    "â”‚   â”œâ”€â”€ freshbanana/\n",
    "â”‚   â”œâ”€â”€ freshoranges/\n",
    "â”‚   â”œâ”€â”€ rottenapples/\n",
    "â”‚   â”œâ”€â”€ rottenbanana/\n",
    "â”‚   â”œâ”€â”€ rottenoranges/\n",
    "â”‚   â”œâ”€â”€ unripe apple/\n",
    "â”‚   â”œâ”€â”€ unripe banana/\n",
    "â”‚   â””â”€â”€ unripe orange/\n",
    "â””â”€â”€ test/\n",
    "    â””â”€â”€ (same structure)\n",
    "```\n",
    "\n",
    "**Download process:**\n",
    "1. Created Kaggle account\n",
    "2. Downloaded dataset ZIP file\n",
    "3. Extracted to `data/` folder\n",
    "4. Verified folder structure\n",
    "\n",
    "**No data collection challenges** - dataset was ready to use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Understanding\n",
    "\n",
    "**What it means:** Explore the data to understand what you have.\n",
    "\n",
    "### My Data Analysis\n",
    "\n",
    "**Where:** See `01_Dataset_Analysis.ipynb` for detailed analysis\n",
    "\n",
    "**What I checked:**\n",
    "\n",
    "**1. Dataset size:**\n",
    "- Training images: 16,217\n",
    "- Test images: 3,739\n",
    "- Total: 19,956 images\n",
    "\n",
    "**2. Class distribution:**\n",
    "- Checked if classes are balanced\n",
    "- Found some classes have more images than others\n",
    "- Calculated imbalance ratio to see if it's a problem\n",
    "\n",
    "**3. Image characteristics:**\n",
    "- Image size: Varies (will need to resize to 224Ã—224)\n",
    "- Format: JPG\n",
    "- Color: RGB (3 channels)\n",
    "- Quality: Good, clear images\n",
    "\n",
    "**4. Visual inspection:**\n",
    "- Viewed sample images from each class\n",
    "- Confirmed ripeness labels look correct\n",
    "- Checked for obvious errors or mislabeled images\n",
    "\n",
    "**5. Train/Test split:**\n",
    "- Already split by the dataset creator\n",
    "- Ratio: 81% train / 19% test (good split)\n",
    "- No overlap between train and test (verified)\n",
    "\n",
    "**Key findings:**\n",
    "- Dataset is big enough for training\n",
    "- Images are clear and well-labeled\n",
    "- Some class imbalance, but not severe\n",
    "- Good variety in angles and lighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Data Preparation\n",
    "\n",
    "**What it means:** Process and transform the data to make it ready for the model.\n",
    "\n",
    "### My Data Preparation\n",
    "\n",
    "**Where:** See `02_Model_Training.ipynb` for implementation\n",
    "\n",
    "**What I did:**\n",
    "\n",
    "**1. Image Preprocessing:**\n",
    "- Resize all images to 224Ã—224 pixels (MobileNetV2 requirement)\n",
    "- Normalize pixel values from [0, 255] to [0, 1]\n",
    "- Convert to float32 data type\n",
    "\n",
    "**2. Data Augmentation (training only):**\n",
    "- **Rotation:** Â±20Â° (fruit can be tilted)\n",
    "- **Horizontal flip:** Mirror image\n",
    "- **Zoom:** Â±20% (fruit can be closer/farther)\n",
    "- **Shift:** Â±20% (fruit not always centered)\n",
    "- **Brightness:** Â±20% (different lighting)\n",
    "\n",
    "**Why augmentation?**\n",
    "- Creates more training variety\n",
    "- Prevents overfitting (memorization)\n",
    "- Model learns to recognize fruit from any angle/lighting\n",
    "- Makes model more robust for real-world use\n",
    "\n",
    "**3. Batching:**\n",
    "- Batch size: 32 images per batch\n",
    "- Why? GPU memory limitations + good training stability\n",
    "\n",
    "**4. Label Encoding:**\n",
    "- One-hot encoding for 9 classes\n",
    "- Example: \"freshapples\" â†’ [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "**No manual cleaning needed** - dataset was already clean!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Modeling\n",
    "\n",
    "**What it means:** Build and train the machine learning model.\n",
    "\n",
    "### My Model\n",
    "\n",
    "**Where:** See `02_Model_Training.ipynb` for full training process\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "```\n",
    "Input: 224Ã—224Ã—3 image\n",
    "    â†“\n",
    "MobileNetV2 Base (FROZEN)\n",
    "    - Pre-trained on ImageNet\n",
    "    - Extracts features (edges, textures, shapes)\n",
    "    â†“\n",
    "GlobalAveragePooling2D\n",
    "    - Reduces dimensions\n",
    "    â†“\n",
    "Dense(256) + ReLU\n",
    "    - Learns fruit-specific patterns\n",
    "    â†“\n",
    "Dropout(0.5)\n",
    "    - Prevents overfitting\n",
    "    â†“\n",
    "Dense(9) + Softmax\n",
    "    - 9 class probabilities\n",
    "    â†“\n",
    "Output: Predicted class\n",
    "```\n",
    "\n",
    "**Training configuration:**\n",
    "- **Optimizer:** Adam (learning_rate=0.0001)\n",
    "- **Loss function:** Categorical crossentropy\n",
    "- **Metrics:** Accuracy\n",
    "- **Epochs:** 50 (with early stopping)\n",
    "- **Batch size:** 32\n",
    "\n",
    "**Why these choices?**\n",
    "- Adam optimizer: Works well for most problems, adapts learning rate automatically\n",
    "- Low learning rate: Fine-tuning needs small steps\n",
    "- Categorical crossentropy: Standard for multi-class classification\n",
    "- Early stopping: Stops when accuracy plateaus (prevents overfitting)\n",
    "\n",
    "**Training time:** ~12 hours on CPU\n",
    "\n",
    "**Model size:** 31 MB (small enough for mobile!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Evaluation\n",
    "\n",
    "**What it means:** Test the model and measure how well it works.\n",
    "\n",
    "### My Evaluation Results\n",
    "\n",
    "**Test accuracy:** 99.8%\n",
    "\n",
    "**Wait, this seems too good?**\n",
    "\n",
    "Actually, I got such high accuracy because:\n",
    "- Dataset is very clean and consistent\n",
    "- Images have clear ripeness indicators\n",
    "- Transfer learning with MobileNetV2 is powerful\n",
    "- Good data augmentation prevented overfitting\n",
    "\n",
    "**But does it work in real life?**\n",
    "\n",
    "That's why I created the prediction tracking system:\n",
    "- SQLite database saves every prediction\n",
    "- Can test on real photos and track accuracy\n",
    "- Compare test set accuracy vs. real-world accuracy\n",
    "\n",
    "**Performance metrics:**\n",
    "- **Training accuracy:** 99.8%\n",
    "- **Validation accuracy:** 99.8%\n",
    "- **Test accuracy:** 99.8%\n",
    "- **Training loss:** 0.012\n",
    "- **No overfitting!** (train/val accuracies match)\n",
    "\n",
    "**What I checked:**\n",
    "1. Overall accuracy (99.8% âœ“)\n",
    "2. Per-class accuracy (all classes > 98% âœ“)\n",
    "3. Confusion matrix (very few mistakes âœ“)\n",
    "4. Confidence levels (mostly > 90% âœ“)\n",
    "\n",
    "**Success criteria met:** âœ… Target was â‰¥85%, achieved 99.8%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Deployment\n",
    "\n",
    "**What it means:** Make the model available for use.\n",
    "\n",
    "### My Deployment Plan\n",
    "\n",
    "**Current status:** Model is trained and saved\n",
    "\n",
    "**Phase 1: Python Scripts (âœ… DONE)**\n",
    "- Command-line prediction: `python scripts/predict.py image.jpg`\n",
    "- Database tracking: All predictions saved automatically\n",
    "- Visualization tools: View prediction history\n",
    "\n",
    "**Phase 2: Web Demo (PLANNED)**\n",
    "- Flask web app\n",
    "- Upload image or use webcam\n",
    "- Get instant prediction with confidence\n",
    "- Show prediction history\n",
    "\n",
    "**Phase 3: Mobile App (FUTURE)**\n",
    "- Convert to TensorFlow Lite (.tflite)\n",
    "- Build Flutter app\n",
    "- Camera integration\n",
    "- Offline predictions (no internet needed)\n",
    "\n",
    "**Why this order?**\n",
    "1. Scripts first â†’ Quick testing and validation\n",
    "2. Web app second â†’ Demo for teachers/portfolio\n",
    "3. Mobile app last â†’ Full product (takes more time)\n",
    "\n",
    "**Deployment files created:**\n",
    "- `models/fruit_classifier.keras` (trained model)\n",
    "- `models/class_labels.json` (class names)\n",
    "- `models/training_config.json` (training info)\n",
    "- `scripts/predict.py` (prediction script)\n",
    "- `scripts/db_helper.py` (database functions)\n",
    "- `predictions.db` (SQLite database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Feedback\n",
    "\n",
    "**What it means:** Get feedback, monitor performance, and improve the model.\n",
    "\n",
    "### My Feedback System\n",
    "\n",
    "**How I track feedback:**\n",
    "\n",
    "**1. Database System**\n",
    "- Every prediction saved to `predictions.db`\n",
    "- Tracks: image, prediction, confidence, timestamp\n",
    "- Can mark predictions as correct/incorrect\n",
    "\n",
    "**2. Performance Monitoring**\n",
    "```python\n",
    "# Check accuracy on real images\n",
    "python scripts/view_history.py\n",
    "\n",
    "# Visualize results\n",
    "python scripts/visualize_predictions.py\n",
    "```\n",
    "\n",
    "**3. Error Analysis**\n",
    "- Query database for wrong predictions\n",
    "- See which fruits get confused\n",
    "- Example: \"Does it confuse unripe bananas with fresh bananas?\"\n",
    "\n",
    "**What to look for:**\n",
    "- Real-world accuracy lower than test accuracy? â†’ Need more diverse training data\n",
    "- Specific class performing badly? â†’ Need more examples of that class\n",
    "- Low confidence predictions? â†’ Model is uncertain, might need retraining\n",
    "\n",
    "**Improvement plan:**\n",
    "1. Test on 100 real fruit photos\n",
    "2. Calculate real-world accuracy\n",
    "3. If < 85%, retrain with more augmentation\n",
    "4. If specific fruit fails, add more training images for it\n",
    "5. Repeat until real-world accuracy â‰¥ 85%\n",
    "\n",
    "**Feedback loop:**\n",
    "```\n",
    "Use model â†’ Save predictions â†’ Analyze errors â†’ \n",
    "Collect more data â†’ Retrain â†’ Test again â†’ Deploy\n",
    "```\n",
    "\n",
    "**Why this matters:**\n",
    "- Test data might not match real-world conditions\n",
    "- Continuous improvement based on actual usage\n",
    "- Builds trust in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Complete IBM AI Methodology Applied\n",
    "\n",
    "| Step | What I Did | Where to See It |\n",
    "|------|-----------|----------------|\n",
    "| 1. Business Understanding | Identified fruit shopping problem, defined success criteria (â‰¥85% accuracy) | This notebook |\n",
    "| 2. Analytic Approach | Chose CNN + Transfer Learning (MobileNetV2) | This notebook |\n",
    "| 3. Data Requirements | Defined need for 9-class fruit images, ~2000 per class | This notebook |\n",
    "| 4. Data Collection | Downloaded Kaggle dataset (20K images) | `data/` folder |\n",
    "| 5. Data Understanding | Analyzed dataset size, distribution, quality | `01_Dataset_Analysis.ipynb` |\n",
    "| 6. Data Preparation | Preprocessing, augmentation, batching | `02_Model_Training.ipynb` |\n",
    "| 7. Modeling | Built and trained MobileNetV2 model (50 epochs) | `02_Model_Training.ipynb` |\n",
    "| 8. Evaluation | Tested model, achieved 99.8% accuracy | `02_Model_Training.ipynb` |\n",
    "| 9. Deployment | Created prediction scripts, database system | `scripts/predict.py` |\n",
    "| 10. Feedback | Database tracking, error analysis tools | `scripts/visualize_predictions.py` |\n",
    "\n",
    "---\n",
    "\n",
    "## Project Status\n",
    "\n",
    "âœ… **Completed:**\n",
    "- Data analysis\n",
    "- Model training\n",
    "- Model evaluation\n",
    "- Prediction scripts\n",
    "- Database system\n",
    "\n",
    "ðŸ”„ **In Progress:**\n",
    "- Real-world testing\n",
    "- Performance monitoring\n",
    "\n",
    "ðŸ“… **Planned:**\n",
    "- Flask web demo\n",
    "- Mobile app (TensorFlow Lite)\n",
    "\n",
    "---\n",
    "\n",
    "**Student:** Maria Paula Salazar Agudelo  \n",
    "**Course:** AI Minor - Personal Challenge  \n",
    "**Date:** 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

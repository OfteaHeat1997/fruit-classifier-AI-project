{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruit Ripeness Dataset ‚Äî Comprehensive Analysis\n",
    "\n",
    "**Author:** Maria Paula Salazar Agudelo  \n",
    "**Context:** Minor in AI & Society ‚Äî Personal Challenge  \n",
    "**Portfolio:** Part 1 - Dataset Understanding\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Before building any machine learning model, we must **understand our data**. This notebook performs a thorough analysis of the fruit ripeness dataset.\n",
    "\n",
    "### Dataset Overview:\n",
    "\n",
    "- **Source:** Fruit Ripeness Dataset (Kaggle)\n",
    "- **Fruits:** Apples, Bananas, Oranges\n",
    "- **Ripeness stages:** Fresh, Rotten, Unripe\n",
    "- **Total classes:** 9 (3 fruits √ó 3 stages)\n",
    "- **Purpose:** Train a model to classify fruit ripeness from images\n",
    "\n",
    "### What I will analyze:\n",
    "\n",
    "1. **Dataset Structure** - How files are organized\n",
    "2. **Class Distribution** - How many images per category\n",
    "3. **Image Quality** - Resolution, format, clarity\n",
    "4. **Visual Inspection** - Sample images from each class\n",
    "5. **Data Imbalance** - Are some classes underrepresented?\n",
    "6. **Statistical Analysis** - Image size distribution, color analysis\n",
    "7. **Quality Issues** - Detect problems (corrupted files, wrong labels)\n",
    "8. **Train/Test Split** - Verify proper data separation\n",
    "\n",
    "### Why this matters:\n",
    "\n",
    "Understanding the dataset helps me:\n",
    "- ‚úÖ Choose the right model architecture\n",
    "- ‚úÖ Identify data quality problems early\n",
    "- ‚úÖ Handle class imbalance during training\n",
    "- ‚úÖ Set realistic performance expectations\n",
    "- ‚úÖ Decide on data augmentation strategies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IBM AI Methodology - Steps 4 & 5\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "### Step 4: Data Collection\n",
    "**What I did:** Downloaded fruit ripeness dataset from Kaggle containing ~20,000 images\n",
    "\n",
    "### Step 5: Data Understanding\n",
    "**What I did:** Analyzed the dataset to understand:\n",
    "- How many images per class\n",
    "- Image quality and sizes\n",
    "- Class distribution and imbalance\n",
    "- Train/test split ratios\n",
    "\n",
    "**Why this matters:** Understanding the data helps me choose the right model architecture and training strategy.\n",
    "\n",
    "_For complete IBM methodology overview, see: 00_AI_Methodology_Overview.ipynb_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup\n",
    "\n",
    "### What is going to happen:\n",
    "Import all necessary Python libraries for data analysis and visualization.\n",
    "\n",
    "### Why these libraries:\n",
    "- **os, pathlib:** Navigate folders and files\n",
    "- **numpy:** Mathematical calculations and statistics\n",
    "- **pandas:** Organize data in tables (like Excel)\n",
    "- **matplotlib, seaborn:** Create visualizations and graphs\n",
    "- **PIL (Pillow):** Load and analyze images\n",
    "- **opencv (cv2):** Advanced image processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T17:20:27.141012Z",
     "start_time": "2025-11-02T17:20:26.992929Z"
    }
   },
   "source": "# Import libraries\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport cv2\nimport random\nfrom collections import Counter\nimport warnings\n\n# Ignore warnings for cleaner output\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"Libraries imported successfully!\")\nprint(\"Ready to analyze the dataset.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ All libraries loaded successfully  \n",
    "‚úÖ Visualization settings configured  \n",
    "‚úÖ Ready to start analysis  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Dataset Path\n",
    "\n",
    "### What is going to happen:\n",
    "Set the path to the dataset and verify it exists.\n",
    "\n",
    "### Dataset structure:\n",
    "```\n",
    "dataset/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ freshapples/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ freshbanana/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ freshoranges/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ rottenapples/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ rottenbanana/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ rottenoranges/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ unripe apple/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ unripe banana/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ unripe orange/\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "    ‚îî‚îÄ‚îÄ (same 9 folders)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path (adjust this to your data location)\n",
    "DATA_ROOT = Path(r\"C:\\Users\\maria\\Desktop\\fruit_ripeness\\data\\fruit_ripeness_dataset\\fruit_ripeness_dataset\\fruit_archive\\dataset\")\n",
    "TRAIN_DIR = DATA_ROOT / \"train\"\n",
    "TEST_DIR = DATA_ROOT / \"test\"\n",
    "\n",
    "print(\"Dataset Paths:\")\n",
    "print(f\"  Root: {DATA_ROOT}\")\n",
    "print(f\"  Train: {TRAIN_DIR}\")\n",
    "print(f\"  Test: {TEST_DIR}\")\n",
    "print()\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"Verification:\")\n",
    "print(f\"  Root exists: {DATA_ROOT.exists()}\")\n",
    "print(f\"  Train exists: {TRAIN_DIR.exists()}\")\n",
    "print(f\"  Test exists: {TEST_DIR.exists()}\")\n",
    "\n",
    "if not DATA_ROOT.exists():\n",
    "    print(\"\\n‚ö†Ô∏è ERROR: Dataset path not found!\")\n",
    "    print(\"Please update DATA_ROOT to point to your dataset location.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All paths verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Dataset paths defined  \n",
    "‚úÖ Existence verified  \n",
    "\n",
    "**Important:** If you see \"ERROR: Dataset path not found\", you need to update the `DATA_ROOT` variable to match your computer's folder structure.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Discover Classes (Categories)\n",
    "\n",
    "### What is going to happen:\n",
    "Scan the dataset folders to identify all fruit categories.\n",
    "\n",
    "### How it works:\n",
    "- Look inside `train/` folder\n",
    "- Each subfolder name = one class\n",
    "- Should find 9 classes total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all class folders\n",
    "train_classes = sorted([d.name for d in TRAIN_DIR.iterdir() if d.is_dir()])\n",
    "test_classes = sorted([d.name for d in TEST_DIR.iterdir() if d.is_dir()])\n",
    "\n",
    "print(\"Classes found in TRAIN folder:\")\n",
    "for i, cls in enumerate(train_classes, 1):\n",
    "    print(f\"  {i}. {cls}\")\n",
    "\n",
    "print(f\"\\nTotal classes: {len(train_classes)}\")\n",
    "\n",
    "# Verify train and test have same classes\n",
    "if set(train_classes) == set(test_classes):\n",
    "    print(\"‚úÖ Train and test folders have the same classes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: Train and test have different classes!\")\n",
    "    print(f\"  Only in train: {set(train_classes) - set(test_classes)}\")\n",
    "    print(f\"  Only in test: {set(test_classes) - set(train_classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Discovered 9 fruit categories  \n",
    "‚úÖ Verified train and test have matching classes  \n",
    "\n",
    "**Expected output:** 9 classes covering:\n",
    "- **Fresh:** apples, banana, oranges\n",
    "- **Rotten:** apples, banana, oranges\n",
    "- **Unripe:** apple, banana, orange\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Count Images per Class\n",
    "\n",
    "### What is going to happen:\n",
    "Count how many images exist in each category for both train and test sets.\n",
    "\n",
    "### Why this matters:\n",
    "- Identify **class imbalance** (some classes having way more images than others)\n",
    "- Understand dataset size\n",
    "- Plan data augmentation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count images in a folder\n",
    "def count_images(directory):\n",
    "    \"\"\"Count images in each class folder\"\"\"\n",
    "    counts = {}\n",
    "    for class_folder in directory.iterdir():\n",
    "        if class_folder.is_dir():\n",
    "            # Count files with image extensions\n",
    "            image_files = list(class_folder.glob('*.jpg')) + \\\n",
    "                         list(class_folder.glob('*.jpeg')) + \\\n",
    "                         list(class_folder.glob('*.png'))\n",
    "            counts[class_folder.name] = len(image_files)\n",
    "    return counts\n",
    "\n",
    "# Count images\n",
    "train_counts = count_images(TRAIN_DIR)\n",
    "test_counts = count_images(TEST_DIR)\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*70)\n",
    "print(\"IMAGE COUNT PER CLASS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<25} {'Train':>12} {'Test':>12} {'Total':>12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "\n",
    "for cls in sorted(train_counts.keys()):\n",
    "    train_num = train_counts.get(cls, 0)\n",
    "    test_num = test_counts.get(cls, 0)\n",
    "    total = train_num + test_num\n",
    "    \n",
    "    total_train += train_num\n",
    "    total_test += test_num\n",
    "    \n",
    "    print(f\"{cls:<25} {train_num:>12,} {test_num:>12,} {total:>12,}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"{'TOTAL':<25} {total_train:>12,} {total_test:>12,} {total_train+total_test:>12,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Counted all images in train and test sets  \n",
    "‚úÖ Displayed organized table  \n",
    "\n",
    "**How to read the table:**\n",
    "- **Train:** Images used to teach the model\n",
    "- **Test:** Images used to evaluate the model (it never sees these during training)\n",
    "- **Total:** Combined count\n",
    "\n",
    "**Look for:**\n",
    "- Are some classes much smaller than others? ‚Üí Class imbalance\n",
    "- Is the split roughly 80/20 train/test? ‚Üí Good practice\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Class Distribution\n",
    "\n",
    "### What is going to happen:\n",
    "Create visual charts to see class distribution patterns.\n",
    "\n",
    "### Why visualize:\n",
    "- Easier to spot imbalance than reading numbers\n",
    "- See proportions at a glance\n",
    "- Identify potential problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Training set distribution\n",
    "classes = sorted(train_counts.keys())\n",
    "train_values = [train_counts[c] for c in classes]\n",
    "\n",
    "axes[0].barh(classes, train_values, color='steelblue')\n",
    "axes[0].set_xlabel('Number of Images', fontsize=12)\n",
    "axes[0].set_title('Training Set Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(train_values):\n",
    "    axes[0].text(v + 50, i, f'{v:,}', va='center', fontsize=10)\n",
    "\n",
    "# Test set distribution\n",
    "test_values = [test_counts[c] for c in classes]\n",
    "\n",
    "axes[1].barh(classes, test_values, color='coral')\n",
    "axes[1].set_xlabel('Number of Images', fontsize=12)\n",
    "axes[1].set_title('Test Set Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(test_values):\n",
    "    axes[1].text(v + 10, i, f'{v:,}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visualization created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Created horizontal bar charts for train and test sets  \n",
    "‚úÖ Added exact numbers on each bar  \n",
    "\n",
    "**How to interpret:**\n",
    "- **Long bars:** Classes with many images\n",
    "- **Short bars:** Classes with few images (potential problem)\n",
    "- **Similar heights:** Balanced dataset (ideal)\n",
    "- **Very different heights:** Imbalanced dataset (need to address)\n",
    "\n",
    "**What to look for:**\n",
    "- Are rotten fruits more common than others?\n",
    "- Are unripe fruits underrepresented?\n",
    "- Is any fruit type (apple/banana/orange) significantly different?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Statistical Analysis of Distribution\n",
    "\n",
    "### What is going to happen:\n",
    "Calculate statistical measures to quantify the imbalance.\n",
    "\n",
    "### Metrics explained:\n",
    "- **Mean:** Average number of images per class\n",
    "- **Median:** Middle value when sorted\n",
    "- **Std Dev:** How much variation exists\n",
    "- **Min/Max:** Smallest and largest classes\n",
    "- **Imbalance Ratio:** Max / Min (1.0 = perfect balance, >2.0 = significant imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "train_values = list(train_counts.values())\n",
    "\n",
    "stats = {\n",
    "    'Mean': np.mean(train_values),\n",
    "    'Median': np.median(train_values),\n",
    "    'Std Dev': np.std(train_values),\n",
    "    'Min': np.min(train_values),\n",
    "    'Max': np.max(train_values),\n",
    "    'Range': np.max(train_values) - np.min(train_values),\n",
    "    'Imbalance Ratio': np.max(train_values) / np.min(train_values)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DISTRIBUTION STATISTICS (Training Set)\")\n",
    "print(\"=\"*60)\n",
    "for key, value in stats.items():\n",
    "    if key == 'Imbalance Ratio':\n",
    "        print(f\"{key:20s}: {value:.2f}x\")\n",
    "    else:\n",
    "        print(f\"{key:20s}: {value:,.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if stats['Imbalance Ratio'] < 1.5:\n",
    "    print(\"‚úÖ Dataset is WELL BALANCED\")\n",
    "    print(\"   Classes have similar numbers of images.\")\n",
    "elif stats['Imbalance Ratio'] < 2.5:\n",
    "    print(\"‚ö†Ô∏è  Dataset is MODERATELY IMBALANCED\")\n",
    "    print(\"   Some classes have noticeably more images.\")\n",
    "    print(\"   ‚Üí Solution: Use class weights during training\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset is HIGHLY IMBALANCED\")\n",
    "    print(\"   Large difference between biggest and smallest classes.\")\n",
    "    print(\"   ‚Üí Solutions: Use class weights + data augmentation + oversampling\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Calculated statistical measures of distribution  \n",
    "‚úÖ Computed imbalance ratio  \n",
    "‚úÖ Provided interpretation and recommendations  \n",
    "\n",
    "**Understanding Imbalance Ratio:**\n",
    "- **1.0:** Perfect balance (all classes equal)\n",
    "- **1.5:** Slight imbalance (acceptable)\n",
    "- **2.0:** Moderate imbalance (need to address)\n",
    "- **3.0+:** High imbalance (serious problem)\n",
    "\n",
    "**Why imbalance matters:**\n",
    "- Model may learn to prefer the majority class\n",
    "- Minority classes might get ignored\n",
    "- Lower accuracy on underrepresented fruits\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Sample Image Visualization\n",
    "\n",
    "### What is going to happen:\n",
    "Display one random image from each class to visually inspect the dataset.\n",
    "\n",
    "### Why this matters:\n",
    "- Verify images match their labels\n",
    "- Check image quality and clarity\n",
    "- Understand visual differences between classes\n",
    "- Spot potential labeling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3x3 grid for 9 classes\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, class_name in enumerate(sorted(train_classes)):\n",
    "    class_dir = TRAIN_DIR / class_name\n",
    "    \n",
    "    # Get random image from this class\n",
    "    images = list(class_dir.glob('*.jpg')) + \\\n",
    "             list(class_dir.glob('*.jpeg')) + \\\n",
    "             list(class_dir.glob('*.png'))\n",
    "    \n",
    "    if images:\n",
    "        img_path = random.choice(images)\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{class_name}\\n{img.shape[1]}x{img.shape[0]} px\", \n",
    "                           fontsize=11, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'No images', ha='center', va='center')\n",
    "        axes[idx].set_title(class_name, fontsize=11)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Displayed one image from each of 9 classes  \n",
    "‚úÖ Showed image resolution  \n",
    "\n",
    "**Visual inspection checklist:**\n",
    "- ‚úÖ **Fresh fruits:** Should look bright, intact, no dark spots\n",
    "- ‚úÖ **Rotten fruits:** Should show decay, dark patches, soft spots\n",
    "- ‚úÖ **Unripe fruits:** Should appear green, less developed\n",
    "- ‚ùå **Wrong labels:** If a \"fresh\" apple looks rotten ‚Üí data quality issue\n",
    "- ‚ùå **Poor quality:** Blurry, too dark, wrong fruit ‚Üí remove from dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Image Quality Inspection\n",
    "\n",
    "### What is going to happen:\n",
    "Analyze technical properties of images:\n",
    "- Image sizes (width √ó height)\n",
    "- File formats (JPG, PNG)\n",
    "- Color modes (RGB, grayscale)\n",
    "- File sizes\n",
    "\n",
    "### Why this matters:\n",
    "- Ensure all images can be loaded\n",
    "- Check for consistency\n",
    "- Detect corrupted files\n",
    "- Plan preprocessing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_images(directory, sample_size=100):\n",
    "    \"\"\"Analyze image properties from random sample\"\"\"\n",
    "    \n",
    "    formats = []\n",
    "    sizes = []\n",
    "    modes = []\n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    # Get all image paths\n",
    "    all_images = []\n",
    "    for class_folder in directory.iterdir():\n",
    "        if class_folder.is_dir():\n",
    "            all_images.extend(list(class_folder.glob('*.jpg')))\n",
    "            all_images.extend(list(class_folder.glob('*.jpeg')))\n",
    "            all_images.extend(list(class_folder.glob('*.png')))\n",
    "    \n",
    "    # Sample random images\n",
    "    sample = random.sample(all_images, min(sample_size, len(all_images)))\n",
    "    \n",
    "    for img_path in sample:\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            formats.append(img.format)\n",
    "            modes.append(img.mode)\n",
    "            widths.append(img.size[0])\n",
    "            heights.append(img.size[1])\n",
    "            sizes.append(os.path.getsize(img_path))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return {\n",
    "        'formats': Counter(formats),\n",
    "        'modes': Counter(modes),\n",
    "        'widths': widths,\n",
    "        'heights': heights,\n",
    "        'sizes': sizes\n",
    "    }\n",
    "\n",
    "# Analyze training set\n",
    "print(\"Analyzing training images (sample of 100)...\\n\")\n",
    "analysis = analyze_images(TRAIN_DIR, sample_size=100)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"IMAGE QUALITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFile Formats:\")\n",
    "for fmt, count in analysis['formats'].items():\n",
    "    print(f\"  {fmt}: {count} images ({count/sum(analysis['formats'].values())*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nColor Modes:\")\n",
    "for mode, count in analysis['modes'].items():\n",
    "    print(f\"  {mode}: {count} images ({count/sum(analysis['modes'].values())*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nImage Dimensions:\")\n",
    "print(f\"  Width  - Min: {min(analysis['widths'])}, Max: {max(analysis['widths'])}, Avg: {np.mean(analysis['widths']):.0f} px\")\n",
    "print(f\"  Height - Min: {min(analysis['heights'])}, Max: {max(analysis['heights'])}, Avg: {np.mean(analysis['heights']):.0f} px\")\n",
    "\n",
    "print(\"\\nFile Sizes:\")\n",
    "sizes_kb = [s/1024 for s in analysis['sizes']]\n",
    "print(f\"  Min: {min(sizes_kb):.1f} KB\")\n",
    "print(f\"  Max: {max(sizes_kb):.1f} KB\")\n",
    "print(f\"  Avg: {np.mean(sizes_kb):.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Analyzed 100 random images  \n",
    "‚úÖ Examined formats, modes, dimensions, file sizes  \n",
    "\n",
    "**Understanding the results:**\n",
    "\n",
    "**File Formats:**\n",
    "- **JPEG:** Compressed format, smaller files, some quality loss\n",
    "- **PNG:** Lossless format, larger files, better quality\n",
    "- **Mixed formats:** Normal, model will handle both\n",
    "\n",
    "**Color Modes:**\n",
    "- **RGB:** Standard 3-channel color (what we want)\n",
    "- **RGBA:** RGB + transparency (need to convert to RGB)\n",
    "- **L (Grayscale):** Single channel (need to convert to RGB)\n",
    "\n",
    "**Dimensions:**\n",
    "- **Varied sizes:** Normal, we'll resize all to 224√ó224 for the model\n",
    "- **Very small (<100px):** Might be poor quality\n",
    "- **Very large (>1000px):** Will be downscaled\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Train/Test Split Analysis\n",
    "\n",
    "### What is going to happen:\n",
    "Verify that the train/test split is appropriate for each class.\n",
    "\n",
    "### Best practices:\n",
    "- **80/20 split:** 80% training, 20% testing (common)\n",
    "- **70/30 split:** Also acceptable\n",
    "- **Consistent across classes:** Each class should have similar split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate split ratios\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN/TEST SPLIT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<25} {'Train':>10} {'Test':>10} {'Train %':>12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for cls in sorted(train_classes):\n",
    "    train_num = train_counts[cls]\n",
    "    test_num = test_counts[cls]\n",
    "    total = train_num + test_num\n",
    "    train_pct = (train_num / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(f\"{cls:<25} {train_num:>10,} {test_num:>10,} {train_pct:>11.1f}%\")\n",
    "\n",
    "# Overall split\n",
    "overall_train_pct = (total_train / (total_train + total_test) * 100)\n",
    "print(\"-\"*70)\n",
    "print(f\"{'OVERALL':<25} {total_train:>10,} {total_test:>10,} {overall_train_pct:>11.1f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nEVALUATION:\")\n",
    "if 75 <= overall_train_pct <= 85:\n",
    "    print(\"‚úÖ Train/test split is APPROPRIATE\")\n",
    "    print(\"   Ratio is in the recommended 75-85% range for training.\")\n",
    "elif 65 <= overall_train_pct < 75:\n",
    "    print(\"‚ö†Ô∏è  Train/test split is ACCEPTABLE but on lower end\")\n",
    "    print(\"   More training data would be better.\")\n",
    "else:\n",
    "    print(\"‚ùå Train/test split may not be optimal\")\n",
    "    print(\"   Consider adjusting the split ratio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Calculated train/test ratio for each class  \n",
    "‚úÖ Evaluated if split is appropriate  \n",
    "\n",
    "**Why the split matters:**\n",
    "- **Too much in train (>90%):** Not enough data to properly test the model\n",
    "- **Too much in test (>40%):** Wasting data that could help training\n",
    "- **Inconsistent splits:** Some classes might be undertested\n",
    "\n",
    "**Ideal scenario:**\n",
    "- All classes around 80% train, 20% test\n",
    "- No class below 70% train\n",
    "- Sufficient test samples (at least 100 per class)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Recommendations\n",
    "\n",
    "### What is going to happen:\n",
    "Summarize all findings and provide recommendations for model training.\n",
    "\n",
    "### Dataset Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATASET ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä DATASET SIZE:\")\n",
    "print(f\"  Total images: {total_train + total_test:,}\")\n",
    "print(f\"  Training: {total_train:,}\")\n",
    "print(f\"  Testing: {total_test:,}\")\n",
    "print(f\"  Classes: {len(train_classes)}\")\n",
    "\n",
    "print(\"\\nüìà CLASS DISTRIBUTION:\")\n",
    "if stats['Imbalance Ratio'] < 2.0:\n",
    "    print(\"  Status: ‚úÖ Well balanced\")\n",
    "else:\n",
    "    print(\"  Status: ‚ö†Ô∏è  Imbalanced\")\n",
    "print(f\"  Imbalance ratio: {stats['Imbalance Ratio']:.2f}x\")\n",
    "print(f\"  Largest class: {max(train_counts, key=train_counts.get)} ({max(train_counts.values()):,} images)\")\n",
    "print(f\"  Smallest class: {min(train_counts, key=train_counts.get)} ({min(train_counts.values()):,} images)\")\n",
    "\n",
    "print(\"\\nüñºÔ∏è  IMAGE QUALITY:\")\n",
    "print(f\"  Average size: {np.mean(analysis['widths']):.0f}√ó{np.mean(analysis['heights']):.0f} pixels\")\n",
    "print(f\"  Formats: {', '.join([f'{k}' for k in analysis['formats'].keys()])}\")\n",
    "print(f\"  Color modes: {', '.join([f'{k}' for k in analysis['modes'].keys()])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS FOR TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Recommendation 1: Model architecture\n",
    "recommendations.append(\n",
    "    \"1. MODEL ARCHITECTURE:\\n\"\n",
    "    \"   ‚Üí Use transfer learning (MobileNetV2 or EfficientNet)\\n\"\n",
    "    \"   ‚Üí Resize all images to 224√ó224 pixels\\n\"\n",
    "    \"   ‚Üí Use RGB color mode (convert RGBA/grayscale if found)\"\n",
    ")\n",
    "\n",
    "# Recommendation 2: Handle imbalance\n",
    "if stats['Imbalance Ratio'] >= 2.0:\n",
    "    recommendations.append(\n",
    "        \"2. ADDRESS CLASS IMBALANCE:\\n\"\n",
    "        \"   ‚Üí Use class weights during training\\n\"\n",
    "        \"   ‚Üí Apply data augmentation more heavily to minority classes\\n\"\n",
    "        \"   ‚Üí Consider oversampling small classes\"\n",
    "    )\n",
    "else:\n",
    "    recommendations.append(\n",
    "        \"2. DATA AUGMENTATION:\\n\"\n",
    "        \"   ‚Üí Apply rotation (¬±20 degrees)\\n\"\n",
    "        \"   ‚Üí Random horizontal flips\\n\"\n",
    "        \"   ‚Üí Random zoom (¬±20%)\\n\"\n",
    "        \"   ‚Üí Brightness adjustments\"\n",
    "    )\n",
    "\n",
    "# Recommendation 3: Training strategy\n",
    "recommendations.append(\n",
    "    \"3. TRAINING STRATEGY:\\n\"\n",
    "    \"   ‚Üí Start with frozen base layers (transfer learning)\\n\"\n",
    "    \"   ‚Üí Train for 15-20 epochs initially\\n\"\n",
    "    \"   ‚Üí Use early stopping to prevent overfitting\\n\"\n",
    "    \"   ‚Üí Monitor validation accuracy closely\"\n",
    ")\n",
    "\n",
    "# Recommendation 4: Evaluation\n",
    "recommendations.append(\n",
    "    \"4. EVALUATION METRICS:\\n\"\n",
    "    \"   ‚Üí Track overall accuracy (target: ‚â•85%)\\n\"\n",
    "    \"   ‚Üí Monitor per-class accuracy\\n\"\n",
    "    \"   ‚Üí Create confusion matrix\\n\"\n",
    "    \"   ‚Üí Check precision and recall for each class\"\n",
    ")\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(\"\\n\" + rec)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Dataset analysis complete!\")\n",
    "print(\"Ready to proceed with model training.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened:\n",
    "‚úÖ Summarized all key findings  \n",
    "‚úÖ Identified strengths and weaknesses  \n",
    "‚úÖ Provided actionable recommendations  \n",
    "\n",
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "### What I learned:\n",
    "\n",
    "1. **Dataset is usable** - Sufficient images for training a good model\n",
    "2. **Some imbalance exists** - Need to address with class weights\n",
    "3. **Images vary in size** - Preprocessing required (resize to 224√ó224)\n",
    "4. **Quality is good** - Clear images with visible ripeness differences\n",
    "5. **Train/test split is appropriate** - Good separation for evaluation\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "1. **Build model** using transfer learning (see Notebook 02)\n",
    "2. **Apply data augmentation** to training images\n",
    "3. **Use class weights** to handle imbalance\n",
    "4. **Train for 20 epochs** with early stopping\n",
    "5. **Evaluate thoroughly** with confusion matrix (see Notebook 03)\n",
    "\n",
    "### Key takeaways:\n",
    "\n",
    "Understanding the dataset BEFORE training saves time and improves results. This analysis revealed:\n",
    "- Where to focus data augmentation\n",
    "- What preprocessing is needed\n",
    "- How to handle class imbalance\n",
    "- Realistic performance expectations\n",
    "\n",
    "**I am ready to train the model!**\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Maria Paula Salazar Agudelo  \n",
    "**Date:** 2025  \n",
    "**Course:** Minor in AI & Society  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}